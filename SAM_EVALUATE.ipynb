{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def extract_centroids(mask, image=None, save_name=None, save_vis=False, vis_output_dir=None):\n",
    "    if mask is None:\n",
    "        return []\n",
    "\n",
    "    if len(mask.shape) == 2:  \n",
    "        mask_bgr = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "    else:\n",
    "        mask_bgr = mask\n",
    "\n",
    "    hsv = cv2.cvtColor(mask_bgr, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    lower_yellow = np.array([20, 100, 100])\n",
    "    upper_yellow = np.array([30, 255, 255])\n",
    "    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "\n",
    "    contours, _ = cv2.findContours(mask_yellow, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    centroids = []  \n",
    "    for contour in contours:\n",
    "        M = cv2.moments(contour)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "            centroids.append((cx, cy))\n",
    "\n",
    "    if save_vis and image is not None and save_name is not None and vis_output_dir is not None:\n",
    "        image_vis = image.copy()\n",
    "        for cx, cy in centroids:\n",
    "            cv2.circle(image_vis, (cx, cy), 5, (0, 0, 255), -1)\n",
    "        output_path = os.path.join(vis_output_dir, save_name)\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(image_vis, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    return centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_raw_sample(true_image_dir, ground_truth_dir):\n",
    "    image_files = sorted(list(Path(true_image_dir).glob(\"*.jpg\"))) \n",
    "    mask_files = sorted(list(Path(ground_truth_dir).glob(\"*.png\")))\n",
    "\n",
    "    for image_path, mask_path in zip(image_files, mask_files):\n",
    "        print(image_path)\n",
    "        print(mask_path)\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "        image = cv2.imread(str(image_path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        mask = cv2.imread(str(mask_path))\n",
    "        mask_rgb = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        centroids = extract_centroids(mask)\n",
    "\n",
    "        mask_vis = mask.copy()\n",
    "        for cx, cy in centroids:\n",
    "            cv2.circle(mask_vis, (cx, cy), 10, (255, 0, 0), -1)\n",
    "\n",
    "        mask_vis_rgb = cv2.cvtColor(mask_vis, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        ax[0].imshow(image)\n",
    "        ax[0].set_title('IMAGE')\n",
    "        ax[0].axis('off')\n",
    "\n",
    "        ax[1].imshow(mask_rgb)\n",
    "        ax[1].set_title('MASK')\n",
    "        ax[1].axis('off')\n",
    "\n",
    "        ax[2].imshow(mask_vis_rgb)\n",
    "        ax[2].set_title('MASK_WITH_CENTROID')\n",
    "        ax[2].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Call function with paths\n",
    "true_image_dir = \"/mnt/mydisk/CrescerAi/Bhumi/Segment_anything/IMAGES\"\n",
    "ground_truth_dir = \"/mnt/mydisk/CrescerAi/Bhumi/Segment_anything/MASKS\"\n",
    "visualize_raw_sample(true_image_dir, ground_truth_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask(mask, ax, random_color=True):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "from segment_anything import SamAutomaticMaskGenerator\n",
    "\n",
    "sam_checkpoint = \"sam_vit_b_01ec64.pth\"\n",
    "model_type = \"vit_b\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "predictor = SamPredictor(sam)\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def part_mask(original_mask, centroid):\n",
    "    \n",
    "    centroid = centroid.squeeze()\n",
    "    \n",
    "    if len(original_mask.shape) == 3:\n",
    "        gray = cv2.cvtColor(original_mask, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = original_mask.copy()\n",
    "    _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    new_mask = np.zeros_like(gray)\n",
    "\n",
    "    pt = (float(centroid[0]), float(centroid[1]))\n",
    "\n",
    "    for cnt in contours:        \n",
    "        if cv2.pointPolygonTest(cnt, pt, False) >= 0:\n",
    "            cv2.drawContours(new_mask, [cnt], -1, 255, thickness=cv2.FILLED)\n",
    "            break\n",
    "\n",
    "    # plt.figure(figsize=(8, 5))\n",
    "    # plt.imshow(new_mask, cmap='gray')\n",
    "    # plt.scatter(centroid[0], centroid[1], c='red', s=100, marker='x')\n",
    "    # plt.axis('off')\n",
    "    # plt.title('Isolated Patch with Centroid')\n",
    "    # plt.show()\n",
    "\n",
    "    return new_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_iou(org_mask, pred_mask):\n",
    "\n",
    "    pred_mask = pred_mask.astype(bool)\n",
    "\n",
    "    intersection = np.logical_and(org_mask, pred_mask)\n",
    "    union = np.logical_or(org_mask, pred_mask)\n",
    "\n",
    "    if union.sum() == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return intersection.sum() / union.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "\n",
    "def plot_kde(data: List[float]):\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.kdeplot(data, linewidth=3, color=\"red\", fill=True, alpha=0.25)\n",
    "\n",
    "\n",
    "    sns.despine(left=True)\n",
    "    plt.xlim(0, 2)\n",
    "    plt.xlabel('')\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.utils.transforms import ResizeLongestSide\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "RESIZE_TRANSFORM = ResizeLongestSide(sam.image_encoder.img_size)\n",
    "\n",
    "\n",
    "def prepare_image(image, transform, device):\n",
    "    image = transform.apply_image(image)\n",
    "    image = torch.as_tensor(image, device=device)\n",
    "    return image.permute(2, 0, 1).contiguous()\n",
    "\n",
    "image_files = sorted(list(Path(true_image_dir).glob(\"*.jpg\")))\n",
    "mask_files = sorted(list(Path(ground_truth_dir).glob(\"*.png\")))\n",
    "\n",
    "sam_input_images = []\n",
    "image_and_its_mask = {}\n",
    "\n",
    "json_data = []\n",
    "\n",
    "for image_path, mask_path in zip(image_files, mask_files):\n",
    "\n",
    "    image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    mask_name = os.path.splitext(os.path.basename(mask_path))[0]\n",
    "\n",
    "    if image_name == mask_name:\n",
    "        print(image_name)\n",
    "        print(mask_name)\n",
    "        image = cv2.imread(str(image_path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        sam_input_image = prepare_image(image, RESIZE_TRANSFORM, device=sam.device)\n",
    "        sam_input_images.append(sam_input_image)\n",
    "\n",
    "        org_mask = cv2.imread(str(mask_path))\n",
    "        org_mask_rgb = cv2.cvtColor(org_mask, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        centroids = extract_centroids(org_mask)\n",
    "\n",
    "        centroids_tensor = torch.tensor(centroids, device=sam.device)\n",
    "        if centroids_tensor.ndim == 1:\n",
    "            centroids_tensor = centroids_tensor.unsqueeze(0)\n",
    "\n",
    "        sam_input_points = torch.tensor(centroids, dtype=torch.float, device=sam.device)\n",
    "        resized_centroids = RESIZE_TRANSFORM.apply_coords_torch(centroids_tensor, original_size=image.shape[:2])\n",
    "\n",
    "        predictor.set_image(image) \n",
    "        \n",
    "        all_ious = []\n",
    "        for idx , centroid_ in enumerate(centroids_tensor):\n",
    "            input_label = np.ones(1, dtype=int)\n",
    "            input_point = centroid_.cpu().numpy().reshape(1, 2)\n",
    "            masks, scores, logits = predictor.predict(\n",
    "                point_coords=input_point,\n",
    "                point_labels=input_label,\n",
    "                multimask_output=False,\n",
    "            )\n",
    "\n",
    "            print(masks.shape)\n",
    "            # fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "            pred_polys = []\n",
    "            pred_vis_polys = []\n",
    "\n",
    "            all_masks = []\n",
    "\n",
    "            # axs[0].imshow(image, alpha=0.9) \n",
    "            # show_mask(masks[0], axs[0])\n",
    "            # show_points(input_point, input_label, axs[0])\n",
    "            # axs[0].set_title(f\"Mask {1}, Score: {scores[0]:.3f}\", fontsize=14)\n",
    "            # axs[0].axis('off')\n",
    "\n",
    "            # axs[1].imshow(org_mask_rgb)\n",
    "            # show_mask(masks , axs[1])\n",
    "\n",
    "\n",
    "            original_mask_gt = part_mask(original_mask=org_mask_rgb , centroid=centroid_)\n",
    "\n",
    "            iou = compute_iou(original_mask_gt , masks[0])\n",
    "            print(iou)\n",
    "            all_ious.append(iou)\n",
    "\n",
    "\n",
    "            #     polygonization_method, polygonization_kwargs = polygonization_list\n",
    "            #     mask_polys = polygonization_method(mask, **polygonization_kwargs)\n",
    "            #     for mask_poly in mask_polys:\n",
    "            #         coords = list(mask_poly.exterior.coords)[:-1]  # Exclude the repeated last point\n",
    "            #         flat_coords = [coord for point in coords for coord in point]\n",
    "            #         pred_vis_polys.append(flat_coords)\n",
    "\n",
    "            # visualize_sam_masks_with_prompt(image, all_masks, pred_vis_polys)\n",
    "\n",
    "            image_and_its_mask[image_path.name] = all_masks\n",
    "\n",
    "            # plt.tight_layout()\n",
    "            # plt.show()\n",
    "\n",
    "        jj = {\n",
    "            'image': image_name,\n",
    "            'centroids': centroids,\n",
    "            'iou': all_ious\n",
    "        }\n",
    "        json_data.append(jj)\n",
    "\n",
    "        \n",
    "        print(all_ious)\n",
    "        # plot_kde(all_ious)\n",
    "\n",
    "with open(\"images_and_ious.json\", \"w\") as f:\n",
    "    json.dump(json_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048_19456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 1/1 [00:10<00:00, 10.66s/it]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "from segment_anything import SamAutomaticMaskGenerator\n",
    "from segment_anything.utils.transforms import ResizeLongestSide\n",
    "\n",
    "def extract_centroids(mask, image=None, save_name=None, save_vis=False, vis_output_dir=None):\n",
    "    if mask is None:\n",
    "        return []\n",
    "\n",
    "    if len(mask.shape) == 2:  \n",
    "        mask_bgr = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "    else:\n",
    "        mask_bgr = mask\n",
    "\n",
    "    hsv = cv2.cvtColor(mask_bgr, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    lower_yellow = np.array([20, 100, 100])\n",
    "    upper_yellow = np.array([30, 255, 255])\n",
    "    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "\n",
    "    contours, _ = cv2.findContours(mask_yellow, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    centroids = []  \n",
    "    for contour in contours:\n",
    "        M = cv2.moments(contour)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "            centroids.append((cx, cy))\n",
    "\n",
    "    if save_vis and image is not None and save_name is not None and vis_output_dir is not None:\n",
    "        image_vis = image.copy()\n",
    "        for cx, cy in centroids:\n",
    "            cv2.circle(image_vis, (cx, cy), 5, (0, 0, 255), -1)\n",
    "        output_path = os.path.join(vis_output_dir, save_name)\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(image_vis, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    return centroids\n",
    "\n",
    "def compute_iou(org_mask, pred_mask):\n",
    "    pred_mask = pred_mask.astype(bool)\n",
    "    intersection = np.logical_and(org_mask, pred_mask)\n",
    "    union = np.logical_or(org_mask, pred_mask)\n",
    "    if union.sum() == 0:\n",
    "        return 0.0\n",
    "    return intersection.sum() / union.sum()\n",
    "\n",
    "def part_mask(original_mask, centroid):\n",
    "    centroid = centroid.squeeze()\n",
    "    \n",
    "    if len(original_mask.shape) == 3:\n",
    "        gray = cv2.cvtColor(original_mask, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = original_mask.copy()\n",
    "    _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    new_mask = np.zeros_like(gray)\n",
    "\n",
    "    pt = (float(centroid[0]), float(centroid[1]))\n",
    "\n",
    "    for cnt in contours:        \n",
    "        if cv2.pointPolygonTest(cnt, pt, False) >= 0:\n",
    "            cv2.drawContours(new_mask, [cnt], -1, 255, thickness=cv2.FILLED)\n",
    "            break\n",
    "\n",
    "    return new_mask\n",
    "\n",
    "def prepare_image(image, transform, device):\n",
    "    image = transform.apply_image(image)\n",
    "    image = torch.as_tensor(image, device=device)\n",
    "    return image.permute(2, 0, 1).contiguous()\n",
    "\n",
    "sam_checkpoint = \"sam_vit_b_01ec64.pth\"\n",
    "model_type = \"vit_b\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "predictor = SamPredictor(sam)\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "RESIZE_TRANSFORM = ResizeLongestSide(sam.image_encoder.img_size)\n",
    "\n",
    "true_image_dir = \"/mnt/mydisk/CrescerAi/Bhumi/Segment_anything/IMAGES\"\n",
    "ground_truth_dir = \"/mnt/mydisk/CrescerAi/Bhumi/Segment_anything/MASKS\"\n",
    "\n",
    "image_files = sorted(list(Path(true_image_dir).glob(\"*.jpg\")))\n",
    "mask_files = sorted(list(Path(ground_truth_dir).glob(\"*.png\")))\n",
    "\n",
    "sam_input_images = []\n",
    "image_and_its_mask = {}\n",
    "json_data = []\n",
    "\n",
    "for image_path, mask_path in tqdm(zip(image_files, mask_files), total=len(image_files), desc=\"Processing Images\"):\n",
    "    image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    mask_name = os.path.splitext(os.path.basename(mask_path))[0]\n",
    "\n",
    "    if image_name == mask_name:\n",
    "        print(image_name)\n",
    "        image = cv2.imread(str(image_path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        sam_input_image = prepare_image(image, RESIZE_TRANSFORM, device=sam.device)\n",
    "        sam_input_images.append(sam_input_image)\n",
    "\n",
    "        org_mask = cv2.imread(str(mask_path))\n",
    "        org_mask_rgb = cv2.cvtColor(org_mask, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        centroids = extract_centroids(org_mask)\n",
    "        centroids_tensor = torch.tensor(centroids, device=sam.device)\n",
    "        if centroids_tensor.ndim == 1:\n",
    "            centroids_tensor = centroids_tensor.unsqueeze(0)\n",
    "\n",
    "        sam_input_points = torch.tensor(centroids, dtype=torch.float, device=sam.device)\n",
    "        resized_centroids = RESIZE_TRANSFORM.apply_coords_torch(centroids_tensor, original_size=image.shape[:2])\n",
    "\n",
    "        predictor.set_image(image) \n",
    "        \n",
    "        all_ious = []\n",
    "        for centroid_ in centroids_tensor:\n",
    "            input_label = np.ones(1, dtype=int)\n",
    "            input_point = centroid_.cpu().numpy().reshape(1, 2)\n",
    "            masks, scores, logits = predictor.predict(\n",
    "                point_coords=input_point,\n",
    "                point_labels=input_label,\n",
    "                multimask_output=False,\n",
    "            )\n",
    "\n",
    "            original_mask_gt = part_mask(original_mask=org_mask_rgb , centroid=centroid_)\n",
    "            iou = compute_iou(original_mask_gt , masks[0])\n",
    "            all_ious.append(iou)\n",
    "\n",
    "            image_and_its_mask[image_path.name] = masks\n",
    "\n",
    "        jj = {\n",
    "            'image': image_name,\n",
    "            'centroids': centroids,\n",
    "            'iou': all_ious\n",
    "        }\n",
    "        json_data.append(jj)\n",
    "\n",
    "with open(\"images_and_ious.json\", \"w\") as f:\n",
    "    json.dump(json_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "\n",
    "# Load data\n",
    "with open('/mnt/mydisk/CrescerAi/Bhumi/Segment_anything/images_and_ious.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# KDE plotting function\n",
    "def plot_kde(data: List[float], image_name: str, save_dir: str = 'kde_plots'):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.kdeplot(data, linewidth=3, color=\"red\", fill=True, alpha=0.25)\n",
    "    sns.despine(left=True)\n",
    "    plt.xlim(0, 2)\n",
    "    plt.xlabel('IoU')\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(save_dir, f'{image_name}.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Iterate through data and plot\n",
    "for item in data:\n",
    "    image_name = item['image']\n",
    "    iou_values = item['iou']\n",
    "    plot_kde(iou_values, image_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STORED IMAGE_EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048_19456\n",
      "torch.Size([3, 1024, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 1/1 [00:10<00:00, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "from segment_anything import SamAutomaticMaskGenerator\n",
    "from segment_anything.utils.transforms import ResizeLongestSide\n",
    "\n",
    "\n",
    "def prepare_image(image, transform, device):\n",
    "    image = transform.apply_image(image)\n",
    "    image = torch.as_tensor(image, dtype=torch.float32 , device=device)\n",
    "    return image.permute(2, 0, 1).contiguous()\n",
    "\n",
    "sam_checkpoint = \"sam_vit_b_01ec64.pth\"\n",
    "model_type = \"vit_b\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "predictor = SamPredictor(sam)\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "RESIZE_TRANSFORM = ResizeLongestSide(sam.image_encoder.img_size)\n",
    "\n",
    "true_image_dir = \"/mnt/mydisk/CrescerAi/Bhumi/Segment_anything/IMAGES\"\n",
    "ground_truth_dir = \"/mnt/mydisk/CrescerAi/Bhumi/Segment_anything/MASKS\"\n",
    "\n",
    "image_files = sorted(list(Path(true_image_dir).glob(\"*.jpg\")))\n",
    "mask_files = sorted(list(Path(ground_truth_dir).glob(\"*.png\")))\n",
    "\n",
    "embedding_dir = \"encoder_embeddings\"\n",
    "\n",
    "sam_input_images = []\n",
    "image_and_its_mask = {}\n",
    "json_data = []\n",
    "\n",
    "for image_path, mask_path in tqdm(zip(image_files, mask_files), total=len(image_files), desc=\"Processing Images\"):\n",
    "    image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    mask_name = os.path.splitext(os.path.basename(mask_path))[0]\n",
    "\n",
    "    if image_name == mask_name:\n",
    "        print(image_name)\n",
    "        image = cv2.imread(str(image_path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        sam_input_image = prepare_image(image, RESIZE_TRANSFORM, device=sam.device)\n",
    "\n",
    "        print(sam_input_image.shape)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            image_embedding = sam.image_encoder(sam_input_image.unsqueeze(0))\n",
    "            embedding_np = image_embedding.cpu().numpy()\n",
    "            \n",
    "            os.makedirs(embedding_dir, exist_ok=True)\n",
    "            embedding_path = os.path.join(embedding_dir, f\"{image_name}_embedding.npy\")\n",
    "            np.save(embedding_path, embedding_np)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STORED DECODER_WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder weights and biases saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "\n",
    "sam_checkpoint = \"sam_vit_b_01ec64.pth\"\n",
    "sam = sam_model_registry[\"vit_b\"](checkpoint=sam_checkpoint)\n",
    "\n",
    "sam_decoder = sam.mask_decoder\n",
    "torch.save(sam_decoder.state_dict(), \"sam_decoder_weights.pth\")\n",
    "\n",
    "print(\"Decoder weights and biases saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
